{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tabular playground 2021_linear regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDF/KkqcEpLXM12D5lagjJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vbanai/Linear_Logistic_Regression_Projects/blob/main/Tabular_playground_2021_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Tif5dgRgg9"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVs915beR_NJ"
      },
      "source": [
        "! pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j44MP2XSSPhb"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDkJI3FUSQDo"
      },
      "source": [
        "! mkdir - p ~/.kaggle \n",
        "! cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSs_-1bgSSNy"
      },
      "source": [
        "!kaggle competitions download -c tabular-playground-series-jan-2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-bpauJb8Fgv",
        "outputId": "4a676454-6e38-45e6-f056-9a042c961cd5"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"viktorbanai\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"9431db56af1a1a63cab88b4e516a2248\" # key from the json file\n",
        "!kaggle competitions download -c tabular-playground-series-jan-2021 # api copied from kaggle\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 89% 34.0M/38.4M [00:00<00:00, 61.7MB/s]\n",
            "100% 38.4M/38.4M [00:00<00:00, 78.2MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/469k [00:00<?, ?B/s]\n",
            "100% 469k/469k [00:00<00:00, 147MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 38% 9.00M/23.9M [00:00<00:00, 31.4MB/s]\n",
            "100% 23.9M/23.9M [00:00<00:00, 60.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uWOGPOplyr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327fc3fe-42f2-477e-e86e-835299a116a0"
      },
      "source": [
        "!unzip \"/content/sample_submission.csv.zip\" -d \"/content/p/\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/sample_submission.csv.zip\n",
            "  inflating: /content/p/sample_submission.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utGSFUc_mJtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f41e9b-ea25-4a40-cfd8-abb5cc111720"
      },
      "source": [
        "!unzip \"/content/test.csv.zip\" -d \"/content/p/\"\n",
        "!unzip \"/content/train.csv.zip\" -d \"/content/p/\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/test.csv.zip\n",
            "  inflating: /content/p/test.csv     \n",
            "Archive:  /content/train.csv.zip\n",
            "  inflating: /content/p/train.csv    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHNG0i4Kqixa"
      },
      "source": [
        "dataframe_raw = pd.read_csv(\"/content/p/sample_submission.csv\")\n",
        "dataframe_raw.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtFuukeA92J3"
      },
      "source": [
        "dataframe_raw = pd.read_csv(\"/content/p/test.csv\")\n",
        "dataframe_raw.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlUJWls_qvpa"
      },
      "source": [
        "batch_size=32\n",
        "\n",
        "dataframe_test = pd.read_csv(\"/content/p/test.csv\")\n",
        "\n",
        "ID=dataframe_test[['id']].to_numpy(dtype=str)\n",
        "\n",
        "inputs_test_array=dataframe_test[['cont1', 'cont2','cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14']].to_numpy(dtype=np.float32)\n",
        "test_tensor = torch.from_numpy(inputs_test_array)\n",
        "test_dl = DataLoader(test_tensor, batch_size)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyPtWH7NquuS"
      },
      "source": [
        "dataframe_train00=pd.read_csv(\"/content/p/train.csv\")\n",
        "dataframe_train0 = dataframe_train00.copy(deep=True)\n",
        "\n",
        "dataframe_train = dataframe_train0.sample(frac=1, random_state=8)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqM_WljN44ET"
      },
      "source": [
        "inputs_array=dataframe_train[['cont1', 'cont2','cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14']].to_numpy(dtype=np.float32)\n",
        "targets_array=dataframe_train[['target']].to_numpy(dtype=np.float32)\n",
        "\n",
        "inputs_tensor = torch.from_numpy(inputs_array)\n",
        "targets_tensor= torch.from_numpy(targets_array)\n",
        "\n",
        "dataset = TensorDataset(inputs_tensor, targets_tensor)\n",
        "\n",
        "train_ds, val_ds =train_test_split(dataset, test_size=0.15, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HUQAopSAUH6"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size, num_workers=2, pin_memory=True)\n",
        "\n",
        "input_size=14\n",
        "output_size=1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NlfeAokDMRU"
      },
      "source": [
        "class Tabularplayground(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)             \n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)                          \n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        out = self(inputs)         \n",
        "        loss = F.mse_loss(out, targets)                         \n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch\n",
        "        out = self(inputs)\n",
        "        loss = F.mse_loss(out, targets) \n",
        "        acc = accuracy(out, targets)                      \n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        #epoch_acc = torch.stack(batch_accs).mean()\n",
        "        epoch_acc = sum(batch_accs)/len(batch_accs)\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc}\n",
        "    \n",
        "    def epoch_end(self, epoch, result, num_epochs):\n",
        "        # Print result every 20th epoch\n",
        "        if (epoch+1) % 2 == 0 or epoch == num_epochs-1:\n",
        "            print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch+1, result['val_loss'], result['val_acc']))\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    counter=0\n",
        "    for i in range(len(labels)):\n",
        "      if outputs[i]>labels[i]*0.8 and outputs[i]<labels[i]*1.2:\n",
        "        counter +=1\n",
        "    return counter/len(labels)\n",
        "\n",
        "    #return torch.tensor(torch.sum(outputs == labels).item() / len(outputs))\n",
        "    #return torch.tensor(torch.sum(outputs > labels*0.8 and outputs<labels*1.2).item() / len(outputs))\n",
        "\n",
        "\n",
        "model = Tabularplayground()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jwsny0HDZ_r"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu9W-tpFDca7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac4e400-820d-42da-bf37-15fb33701e8c"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxGF41o6Dg6y"
      },
      "source": [
        "model = to_device(Tabularplayground(), device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyYqcMyMD_Ex"
      },
      "source": [
        "\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        train_losses = []\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result, epochs)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPUMRJ0uECUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1301033f-5e38-4ead-c90a-729b1fbd2b89"
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "test_dl=DeviceDataLoader(test_dl, device)\n",
        "to_device(model, device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tabularplayground(\n",
              "  (linear): Linear(in_features=14, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgK9n9JLEGC0",
        "outputId": "5912fd02-1181-4110-d1c2-e333a8fc70b8"
      },
      "source": [
        "num_epochs = 50\n",
        "#opt_func = torch.optim.Adam\n",
        "lr = 0.0001\n",
        "\n",
        "history = fit(num_epochs, lr, model, train_dl, val_dl)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [2], val_loss: 1.5591, val_acc: 0.7919\n",
            "Epoch [4], val_loss: 1.2065, val_acc: 0.8473\n",
            "Epoch [6], val_loss: 1.0408, val_acc: 0.8762\n",
            "Epoch [8], val_loss: 0.9482, val_acc: 0.8943\n",
            "Epoch [10], val_loss: 0.8865, val_acc: 0.9065\n",
            "Epoch [12], val_loss: 0.8403, val_acc: 0.9159\n",
            "Epoch [14], val_loss: 0.8028, val_acc: 0.9226\n",
            "Epoch [16], val_loss: 0.7716, val_acc: 0.9291\n",
            "Epoch [18], val_loss: 0.7448, val_acc: 0.9346\n",
            "Epoch [20], val_loss: 0.7218, val_acc: 0.9393\n",
            "Epoch [22], val_loss: 0.7016, val_acc: 0.9429\n",
            "Epoch [24], val_loss: 0.6842, val_acc: 0.9468\n",
            "Epoch [26], val_loss: 0.6686, val_acc: 0.9480\n",
            "Epoch [28], val_loss: 0.6551, val_acc: 0.9508\n",
            "Epoch [30], val_loss: 0.6430, val_acc: 0.9517\n",
            "Epoch [32], val_loss: 0.6324, val_acc: 0.9542\n",
            "Epoch [34], val_loss: 0.6228, val_acc: 0.9559\n",
            "Epoch [36], val_loss: 0.6143, val_acc: 0.9573\n",
            "Epoch [38], val_loss: 0.6066, val_acc: 0.9584\n",
            "Epoch [40], val_loss: 0.5997, val_acc: 0.9592\n",
            "Epoch [42], val_loss: 0.5935, val_acc: 0.9605\n",
            "Epoch [44], val_loss: 0.5879, val_acc: 0.9615\n",
            "Epoch [46], val_loss: 0.5828, val_acc: 0.9623\n",
            "Epoch [48], val_loss: 0.5782, val_acc: 0.9631\n",
            "Epoch [50], val_loss: 0.5739, val_acc: 0.9634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuZdE71HtKMG"
      },
      "source": [
        "test_result=[]\n",
        "\n",
        "for batch in test_dl:\n",
        "  outputs_test = model(batch)\n",
        "  test_result.append(outputs_test)\n",
        "\n",
        "print(test_result[0])\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khHRVigXz_0O"
      },
      "source": [
        " test_numpy=[]\n",
        " for i in test_result:\n",
        "   i2=i.cpu().detach().numpy()\n",
        "   test_numpy.append(i2)\n",
        "\n",
        "test_numpy_array=np.concatenate(test_numpy)\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvDGJg5_2tAe"
      },
      "source": [
        "id=ID.reshape(1,200000)\n",
        "Test_Numpy_Array=test_numpy_array.reshape(1,200000)\n",
        "\n",
        "\n",
        "\n",
        "arr = np.concatenate((id, Test_Numpy_Array), axis=0)\n",
        "\n",
        "\n",
        "print(\"id\", \"     \", \"target\")\n",
        "\n",
        "for i in range(len(arr[0])):\n",
        "  print(arr[0][i], \" \", arr[1][i])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNuqUNUhPqaC"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open(\"mycsv\", 'w') as f:\n",
        "  thewriter=csv.writer(f)\n",
        "\n",
        "  thewriter.writerow(['id', 'target'])\n",
        "  for i in range(len(arr[0])):\n",
        "    thewriter.writerow([arr[0][i], arr[1][i]])\n",
        "\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skmaFPHvQr1E"
      },
      "source": [
        "finaldoc = pd.read_csv(\"/content/mycsv\")\n",
        "finaldoc.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucM8G1DiRgrv"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('mycsv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}